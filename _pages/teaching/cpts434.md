---
layout: page
title: CPTS 434/534 â€“ Neural Network Design and Application
permalink: /teaching/cpts434/
---

## Course Overview


This course provides an introduction to deep neural networks (DNNs), a key component in modern machine learning.
It includes both {\it theoretical} foundations of basic machine learning, and hands-on {\it implementation} of deep neural networks for some applications. 

This course starts with basic concepts and components in statistical machine learning to shed light on the answers to these questions: (i) {\it what is learning}, (ii) {\it what can be learned}, (iii) {\it how to learn it}, (iv) {\it how well we can learn it}, and (v) {\it what machine learning can do}.

Then we will cover the motivation of DNNs, as modern machine learning methods, over traditional machine learning algorithms in the viewpoint of {\it representation learning}, an important task of deep learning.
As a key type of machine learning method, neural networks themselves have unique properties.
We will discuss 
(i) {\it general frameworks and typical components} in DNNs, 
(ii) the {\it computational challenges} and 
(iii) {\it key principles} to learn DNNs. 


After that we will detail several common types of neural networks that are commonly used for different modalities of data or learning targets, such as 
(i) convolutional neural networks (CNNs) for image data, 
(ii) recurrent neural networks (RNNs) for sequence data, 
(iii) graph neural networks (GNNs) for graph data and
(iv) generative adversarial networks (GANs). 
As introducing these well-established networks, we will also cover some recent open research problems in deep learning such as diffusion models and representation learning.



## Syllabus

- ðŸ“„ **[Course Syllabus, Spring 2025](https://drive.google.com/file/d/1h6CLnr0FMEzwoYk4T1uLa60zqV2_5CGJ/view?usp=sharing)**


## Lecture Schedule

| Lecture | Topic | Slides |
|-----:|-------|--------|
| 1  | \[0\] Syllabus and Overview | [Slides]() |
| 2  | \[ML\] ML Basics  | [Slides]() |
| 3  | \[ML\] PAC Learning  | [Slides]() |
| 4  | \[ML\] ERM and MLE  | [Slides]() |
| 5  | \[NN\] NN Basics  | [Slides]() |
| 6  | \[NN\] Compositing Units in NN  | [Slides]() |
| 7  | \[NN\] MLP Softmax Classifier  | [Slides]() |
| 8  | \[CNN\] Convolutional Layer and CNN  | [Slides]() |
| 9  | \[CNN\] CNN Architectures  | [Slides]() |
| 10 | \[CNN\] Practical Training of CNN  | [Slides]() |
| 11 | \[RNN\] Sequence Data and RNN  | [Slides]() |
| 12 | \[RNN\] LSTM and RNN Architecutres  | [Slides]() |
| 13 | \[RNN\] Attention Mechanism  | [Slides]() |
| 14 | \[RNN\] Transformer and ViT  | [Slides]() |
| 15 | \[GNN\] Graph Data and Representation  | [Slides]() |
| 16 | \[GNN\] GNN  | [Slides]() |
| 17 | \[GenAI\] GAN and VAE  | [Slides]() |
| 18 | \[GenAI\] Diffusion Models  | [Slides]() |
| 19 | \[FM\] Foundation Models  | [Slides]() |
| 20 | \[FM\] Fumtimodal Foundation Models  | [Slides]() |
| 21 | \[FL\] Federated Learning  | [Slides]() |
| 22 | \[UQ\] Conformal Prediction and Mean-Risk Model  | [Slides]() |
| 23 | \[Agent\] Agentic Workflow  | [Slides]() |






